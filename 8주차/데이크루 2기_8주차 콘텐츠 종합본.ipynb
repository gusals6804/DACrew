{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"데이크루 2기_8주차 콘텐츠 종합본","provenance":[],"toc_visible":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 이전 게시물"],"metadata":{"id":"bYYPpCqhmCnj"}},{"cell_type":"markdown","source":["[1편. 이상탐지 너 뭐야?](https://dacon.io/codeshare/4758)  \n","[2편. 신용카드 사기 탐지(1부)](https://dacon.io/codeshare/4833)  \n","[3편. 신용카드 사기 탐지(2부)](https://dacon.io/codeshare/4853)  \n","[4편. 비지도 학습 기반의 머신러닝 기법(1부)](https://dacon.io/codeshare/4874)  \n","[5편. 비지도 학습 기반의 머신러닝 기법(2부)](https://dacon.io/codeshare/4890)  \n","[6편. 비지도 학습 기반의 머신러닝 기법을 활용한 이상탐지(1부)](https://dacon.io/codeshare/4954)    \n","[7편. 비지도 학습 기반의 머신러닝 기법을 활용한 이상탐지(2부)](https://dacon.io/codeshare/5000)"],"metadata":{"id":"IiQUXMSkmJNv"}},{"cell_type":"markdown","source":["## **CONTENTS**\n","\n","#### **1. 신경망**\n","\n","#### **2. 오토인코더 : 인코더와 디코더**\n","\n","#### **3. 과소완전 오토인코더**\n","\n","#### **4. 과대완전 오토인코더**\n","\n","#### **5. 희소 오토인코더**\n","\n","#### **6. 노이즈 제거 오토인코더**\n","\n","#### **7. 변분 오토인코더**"],"metadata":{"id":"7NsQMKy2mJBI"}},{"cell_type":"markdown","source":["## **1.신경망**"],"metadata":{"id":"L9nwi2843Ze7"}},{"cell_type":"markdown","source":["신경망은 생물학의 신경망에서 영감을 얻은 학습 알고리즘입니다.\n","\n","신경망에는 입력층, 하나 이상의 은닉층 및 출력층이 있습니다.\n","\n","은닉층의 계층수에 따라서 얕은 신경망과, 심층 신경망(딥러닝)으로 나뉩니다."],"metadata":{"id":"qkT2YeLo4UTg"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1jF0z6FZ_iOrMZc-lcXBzy9AuVgrb4xyT\"\n","width=600>\n","</div>"],"metadata":{"id":"og_nmsZL3ZVx"}},{"cell_type":"markdown","source":["신경망의 각 계층에는 해당 계층을 구성하는 특정 개수의 노드가 있으며, 각 층의 노드는 다음 층의 노드에 연결됩니다. \n","\n","신경망은 이러한 노드들을 쌓아서 출력층에서 예측값을 도출하는 방식입니다."],"metadata":{"id":"5SaySh4V7b1U"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1ObhlWS8yc09uVRl9CWX3_T1vAKixjOek\"\n","width=\"300\">\n","</div>"],"metadata":{"id":"EUOLMSY858o0"}},{"cell_type":"markdown","source":["노드는 비선형 함수인 활성화 함수로 공급되며, 활성화 함수에는 다양한 종류가 있습니다."],"metadata":{"id":"QOgJ2tPB8bIH"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1emG042GgCOwJkqGGvNJmAVacpShFZOjm\"\n","width = 600>\n","</div>"],"metadata":{"id":"x_9rPZG66lQV"}},{"cell_type":"markdown","source":["이러한 신경망에는 데이터가 어느 방향으로든 흐를 수 있는 순환 신경망(RNN), 컴퓨터 비전에 사용되는 컨볼루션 신경망(CNN) 등의 다양한 종류의 신경망이 있습니다."],"metadata":{"id":"dQhZQH328f8B"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=19mBB1fdQrCMXfFotnNvhUJaPp5YAaECE\"\n","width = 600>\n","</div>"],"metadata":{"id":"97XcEr4U6lmi"}},{"cell_type":"markdown","source":["## **2. 오토인코더 : 인코더와 디코더**"],"metadata":{"id":"0Eyfa5f43yaA"}},{"cell_type":"markdown","source":["오토인코더는 representation learning 작업에 신경망을 활용하는 비지도 학습 방법입니다.\n","\n","[representation learning이란?\\\n","입력 데이터를 기반으로 expectation(기댓값, 기대출력)에 가깝게 만드는 유용한 표현(representation)을 학습(learning)하는 방식을 말합니다.]\n","\n","오토 인코더의 핵심 개념은 새로 학습한 내부 표현을 사용해 가능한 한 원본 관측치에 가깝게 재건한다는 점입니다.\n","\n","오토인코더는 차원 축소 및 자동 피처 엔지니어링 및 학습에 널리 사용되며, 오늘날에는 종종 GAN과 같은 생성 모델을 구축하는데 사용합니다."],"metadata":{"id":"2YxzHP-X8iY9"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=154jmHw4TY86RkKd3k6F67sJ6kJydXbGo\" width=\"600\">\n","</div>"],"metadata":{"id":"HNMIZWx76lzl"}},{"cell_type":"markdown","source":["오토인코더는 인코더와 디코더 두 부분으로 구성됩니다.\n","\n","**인코더**(인지 네트워크)는 입력을 내부 표현으로 변환하는 역할을 수행합니다.\n","\n","**디코더**(생성 네트워크)는 내부 표현을 다시 출력으로 바꾸는 역할을 수행합니다.\n","\n","위 그림은 입력이 3차원이고, 내부표현이 2차원으로 입력 차원이 내부표현의 차원보다 높은 과소완전 오토인코더에 해당합니다."],"metadata":{"id":"UvaNu_EF8lhx"}},{"cell_type":"markdown","source":["## **3. 과소완전 오토인코더**"],"metadata":{"id":"C3rDCCKB33Tw"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1bDXPkww6oKlEvr3F5GAVKkdn9u2crQ4e\" width=\"400\">\n","</div>"],"metadata":{"id":"JD2RS1yJ7wfO"}},{"cell_type":"markdown","source":["과소완전 오토인코더는 인코더가 원본 입력 차원보다 더 적은 수의 차원을 학습하는것을 말합니다. 핵심은 원래의 입력데이터의 압축된 지식표현을 만들도록 네트워크에 병목(bottleneck)을 두는 신경망을 만든다는 것입니다.\n","\n","원본 데이터의 입력 차원수를 훨씬 적은 차원으로 줄이는 차원 축소 과정과 유사한 과정을 거칩니다.\n","\n","오토인코더가 디코더를 이용해 입력을 재구성하기 때문에 출력을 재구성이라고도 부르며, 비용 함수는 입력과 출력의 재구성 오차가 가능한 한 작도록 하는 재구성 함수를 포함합니다.\n"],"metadata":{"id":"ySAOKi2K89R2"}},{"cell_type":"markdown","source":["## **4. 과대완전 오토인코더**"],"metadata":{"id":"Te49Z52D37GG"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1oJjEJY5bD3JFwT7a0V3DFX8krp2kDGsz\" width=\"400\">\n","</div>"],"metadata":{"id":"puNJaJlf74Xt"}},{"cell_type":"markdown","source":["과대완전 오토인코더는 인코더가 원본 입력 차원보다 더 많은 수의 차원을 학습하는것을 말합니다. 성공하기 어렵지만, 과소완전보다 잠재적으로 더욱 강력합니다. 원본 관측치의 값을 더 잘 근사하는 복잡한 표현을 학습할 수 있기 때문입니다.\n","\n","과대완전 오토인코더는 단순히 원본 관측치를 복사하기때문에 과소완전 오토인코더처럼 정보를 효율적이고 함축적으로 추출하도록 강요되지 않습니다.\n","\n","따라서 불필요하게 복잡한 함수를 학습하는것에 대해 신경망에 불이익을 주는 정규화를 사용하여 정규화된 과대완전 오토인코더의 형식으로 사용합니다."],"metadata":{"id":"ivgEVf7_9Asx"}},{"cell_type":"markdown","source":["## **5. 희소 오토인코더**"],"metadata":{"id":"mL8DOZuH39Ad"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1UEXYM_OvSoO2mwGMQPkFhbP7JuNkAzd8\" width=\"400\">\n","</div>"],"metadata":{"id":"at20yvHy8ANu"}},{"cell_type":"markdown","source":["희소 오토인코더는 Hidden layer의 node 수가 input layer의 node 수 보다 많은 overcomplete autoencoder 구조, 즉 과대완전 오토인코더 구조를 기반으로 하고 있으며, overfitting 문제를 해결한 모델입니다.\n","\n","Sparsity parameter을 제어하여 은닉층의 활성화에 규제를 가하는 방법을 사용하며, Hidden node중 매번 일부 node만 사용해서 학습하는 dropout 방식을 활용합니다.\n"],"metadata":{"id":"MnUXLRY89FEi"}},{"cell_type":"markdown","source":["## **6. 노이즈 제거 오토인코더**"],"metadata":{"id":"tHmfAgVG4B1e"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1yLvYrGOEf78b7LFRLUdwDAgqRsdA36LH\" width=\"600\">\n","</div>"],"metadata":{"id":"e7Kki4xH8KTA"}},{"cell_type":"markdown","source":["노이즈 제거 오토인코더는 입력에 포함된 잡음을 제거하는 역할을 하는 오토인코더입니다.\n","\n","노이즈 제거 오토인코더는 입력데이터에 random noise을 추가하는 규제기법을 사용합니다.\n","\n","여기서는 Denoising autoencoder를 가정하는데, 이는 입력 데이터에 어떤 noise를 부여하더라도 manifold 상에서 같은 곳에 위치해야 된다고 가정하는것을 의미합니다."],"metadata":{"id":"XSkTIJ4h9ahs"}},{"cell_type":"markdown","source":["## **7. 변분 오토인코더**"],"metadata":{"id":"hGAmPPOI4G4w"}},{"cell_type":"markdown","source":["<div>\n","<img src=\"https://drive.google.com/uc?id=1VQiCP7cRm22BX2mq0DnR1XXdZX7faOnZ\" width=\"1000\">\n","</div>"],"metadata":{"id":"6WGMG80c8KWz"}},{"cell_type":"markdown","source":["변분 오토인코더로 기존 오토인코더와 전혀 다른 모델로 Decoder의 학습에 중점을 둔 모델입니다.\n","\n","오토인코더는 Encoder의 학습에 목적을 두어, input값을 최대한 정확하게 reconstruction 할 수 있는 적절한 내부 표현을 학습하는데 반해,\n","\n","변분 오토인코더는 training data에서 Encoder를 통해 뽑은 내부 표현인 확률분포와 똑같은 분포를 가진 모델에서 값을 뽑아, 같은 특성을 가지는 새로운 데이터를 생성하는 Decoder의 학습에 중점을 두고 있습니다.\n","\n","latent z는 각 feature의 평균과 분산값을 나타내며, 각 feature가 가우시안 분포를 따른다고 가정합니다.\n","\n","따라서 변분 오토인코더는 input값으로 한국인의 얼굴 입력 데이터가 들어오면 한국인의 얼굴의 확률분포와 똑같은 분포를 가진 모델에서 값을 뽑아 그럴듯한 한국인의 얼굴을 생성하는 모델입니다."],"metadata":{"id":"DXN0HvvO9qYb"}},{"cell_type":"markdown","source":["## **결론**\n","지금까지 오토인코더의 개념과 다양한 오토인코더에 대해서 알아보았습니다.\n","\n","다음 포스팅에는 '오토인코더 실습' 편으로 찾아뵙겠습니다.\n","\n","😊감사합니다😊"],"metadata":{"id":"1S2cORaBJSU_"}},{"cell_type":"markdown","source":["## 참고자료\n","\n","*   활성함수: https://22-22.tistory.com/20\n","\n","*   오토인코더 예제 그림: 핸즈온 머신러닝 2판 675쪽 그림 17-1\n","\n","*   오토인코더: https://hyen4110.tistory.com/37\n","\n","*   희소 오토인코더: https://medium.com/@venkatakrishna.jonnalagadda/sparse-stacked-and-variational-autoencoder-efe5bfe73b64\n","\n","*   노이즈제거 오토인코더: https://medium.com/analytics-vidhya/reconstruct-corrupted-data-using-denoising-autoencoder-python-code-aeaff4b0958e\n","\n","+   Variational 오토인코더: https://wikidocs.net/152474"],"metadata":{"id":"Q7Ne81Y09wDA"}}]}