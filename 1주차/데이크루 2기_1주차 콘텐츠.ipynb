{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[데이크루]1주차_콘텐츠.ipynb의 사본","provenance":[{"file_id":"1FwvA7e6mX3FrdVd17fRZWJdWGfvfmGaW","timestamp":1649734668636}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOg9UEblXUhouTrOoO1a1cA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **이상 탐지 개념 및 머신러닝 기초**"],"metadata":{"id":"8h5hxEIycuK-"}},{"cell_type":"markdown","source":["## **목차**\n","\n","\n","\n","#### 1.이상탐지 개념 및 활용 사례\n","#### 2.지도 학습 기반의 알고리즘 및 이상탐지 기법\n","#### 3.비지도 학습 기반의 알고리즘 및 이상탐지 기법"],"metadata":{"id":"luHiTX7Hcxab"}},{"cell_type":"markdown","source":["### **1.이상탐지 개념 및 활용 사례**"],"metadata":{"id":"oLteFO4iczSi"}},{"cell_type":"markdown","source":["1. 이상탐지 개념\n","    \n","    이상탐지는 데이터 마이닝을 기반으로 한 데이터 분석 기법 중의 하나로, 이상치를 탐지하는 기법입니다. 따라서 이상치, 이상 징후로 부르고, 영어로는 Anomalies, Outliers, Exceptions와 같이 표현될 수 있습니다. 대표적으로 이상탐지는 IT 보안, 의료진단, 제조공정의 모니터링 등 다양한 산업분야에 적용되고 있으며 활용분야가 점차 확대되고 있습니다.\n","    \n","    다음은 이상탐지를 보는 관점에 따라 이상탐지의 정의가 조금씩 달라지는 것을 알 수 있습니다.\n","    \n","    - 점 이상 (Point Anomaly)\n","        - 데이터 내 하나의 관측 값이 나머지에 이상하다고 판단되는 경우\n","        \n","    - 맥락적 이상 (Contextual Anomaly)\n","        - 시간의 특성을 가지는 Time-Series 분야에서 많이 나타납니다.\n","        - 시계열 자료에서는 시간의 연속성이 존재하여 특정 시점이 그 시점 전, 후의 값에 크게 영향을 받습니다.\n","        - 시계열 자료에서 비정상적인 시점을 찾는 것을 목표로 할지, 비정상적인 변화의 패턴을 찾는 것을 목표로 할지에 따라 분류합니다."],"metadata":{"id":"6gwUDahzea6d"}},{"cell_type":"markdown","source":["2. 이상 탐지의 적용 사례\n","    - **Cyber-Intrusion Detection**\n","        \n","        컴퓨터 시스템 상에 침입을 탐지하는 사례. 주로 시계열 데이터를 다루며 RAM, file system, log file 등 일련의 시계열 데이터에 대해 이상치를 검출하여 침입을 탐지합니다.\n","        \n","    - **Fraud Detection**\n","        \n","        보험, 신용, 금융 관련 데이터에서 불법 행위를 검출하는 사례. Kaggle Credit Card Fraud Detection 과 같은 공개된 Challenge도 진행되었습니다.\n","        \n","    - **Malware Detection**\n","        \n","        Malware(악성코드)를 검출해내는 사례. Classification과 Clustering이 주로 사용되며 Malware 데이터를 그대로 이용하기도 하고, 이를 Gray Scale Image로 변환하여 이용하기도 합니다.\n","        \n","    - **Medical Anomaly Detection**\n","        \n","        의료 영상, 뇌파 기록 등의 의학 데이터에 대한 이상치 탐지 사례. 주로 신호 데이터와 이미지 데이터를 다루며 X-ray, CT, MRI, PET 등 다양한 장비로부터 취득된 이미지를 다루고 있습니다.\n","\n","\n","\n","        "],"metadata":{"id":"eKA52TIlebD0"}},{"cell_type":"markdown","source":["3. 비지도 학습에 기반한 이상탐지 활용 사례\n","- **PCA**\n","    \n","    PCA에 의해 선택된 축과 원래의 샘플 위치를 비교하여 거리가 먼 샘플은 비정상이라고 판별합니다.\n","\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9895d265-07a9-42a3-8ec3-5e220769bd52/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T015638Z&X-Amz-Expires=86400&X-Amz-Signature=3d9707b3f38478d6784d5cd17e430623e836ce9d8d0e9c6cd552c5b34641d158&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"250\" height=\"250\">\n","    \n","- **Autoencoder**\n","    \n","    복원 오차는 이상 점수 (Anomaly score) 가 되어 threshold와 비교를 통해 이상 여부를 결정합니다.\n","    \n","    - threshold 보다 클 경우 이상\n","    - threshold 보다 작을 경우 정상\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f079ec32-46a7-4367-bf53-d85c160e62aa/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T021205Z&X-Amz-Expires=86400&X-Amz-Signature=6d601535e1d41da919e3c3c5ee92d26f4774b3fdcffb602647357cd5efd15bac&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"300\">"],"metadata":{"id":"u9pgDk8xg5DV"}},{"cell_type":"markdown","source":["### **2.지도 학습 기반의 알고리즘 및 이상탐지 기법**"],"metadata":{"id":"VOK9vZSvczWk"}},{"cell_type":"markdown","source":["먼저 지도 학습이 무엇인지에 대해 간단히 살펴볼까요?😀\n","\n","지도 학습이란 훈련 데이터로부터 하나의 함수를 유추해내기 위한 기계 학습의 한 방법으로,\n","\n","주어진 데이터에 대해 예측하고자 하는 값을 올바르게 추출하기 위한 목적을 가지고 있습니다.\n","\n","지도 학습은 유추된 함수가 어떤 값을 띄는지에 따라 2개로 분류가 가능합니다.\n","\n","1)  회귀 분석: 연속적인 값을 출력합니다.\n","\n","2)  분류: 비연속적인 값으로 ,어떤 종류의 값인지 출력합니다.\n","\n","지도 학습을 이용한 알고리즘은 매우 다양합니다. **최근접 이웃(k-NN), 선형 모델,****랜덤 포레스트**\n","등이 있으며 저희는 크게  선형 방법, 이웃 기반 방법, 트리 기반 방법 3가지의 기준에 따라 알고리즘을 분류해보았습니다.🤭"],"metadata":{"id":"mxN7gOgdjBR3"}},{"cell_type":"markdown","source":["1.선형 방법\n","\n","선형 회귀 모델이란 파라미터가 선형식으로 표현이 되는 모델을 뜻합니다. 선형 회귀 분석, 로지스틱 회귀 분석과 같은 모델이 선형 회귀 모델에 속합니다.\n"],"metadata":{"id":"IgMmDe-8jEec"}},{"cell_type":"markdown","source":["\n","01)선형 회귀 분석\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1f71d213-f358-46ed-9dc3-3dd84d7fc6a2/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T021401Z&X-Amz-Expires=86400&X-Amz-Signature=3f09be250667845386b39f23a997342962fad37afcbc8e1e9097999d2a01faa0&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"300\">\n","\n","\n","선형 회귀는 입력 변수(x)와 단일 출력 변수(y) 사이의 선형 관계를 가정하는 모델을 사용하는 가장 간단한 알고리즘으로 수치 예측 문제 (추론 문제 ,예측 문제)에 활용됩니다.\n","\n","선형 회귀 분석은 독립변수의 개수에 따라 2가지로 분류되는데요. 독립변수가 1개로 이루어질 경우 단순선형 회귀 모델로 불려지며, 독립변수들로 이루어진 행렬과 종속변수가 주어졌을 때 다중선형 회귀 모델이라고 볼 수 있습니다 ! \n","\n","선형 회귀 분석의 장점으로는 지나치게 복잡한 관계를 모형화할 수 없기 때문에 간단하고 이해하기 쉬우며 과대적합되기 어렵다는 점입니다.그러나 입력 변수와 출력 변수간의 관계가 선형이 아닌 비선형일때 데이터에 과소적합할 위험이 존재합니다.\n","\n","\n"],"metadata":{"id":"6MV4WnkSkBOW"}},{"cell_type":"markdown","source":["\n","\n","\n","\n","02)로지스틱 회귀 분석\n","\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e2f0fa90-9403-4299-9644-b58102336740/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T021632Z&X-Amz-Expires=86400&X-Amz-Signature=5f7762c8a556931fe9198a15453d177a40474c0fcfe877d28d18a28c46eb9c0e&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"300\">\n","\n","\n","로지스틱 회귀 분석은 간단한 분류 알고리즘으로 선형 방법이지만, 종속 변수는 로지스틱 함수에 의해 반환되며 이 변환을 통해 클래스 확률을 출력합니다.\n","\n","Y가 범주형 변수일때 선형 회귀 모델을 그대로 적용하게 될 경우 숫자는 아무 의미를 지니고 있지 않기 때문에 적용한 의미가 없습니다. 이때 , 로지스틱을 사용합니다. \n","\n","즉, 로지스틱 회귀 분석은 종속 변수가 연속형이 아닌 범주형 데이터로 주어져 해당 데이터의 결과가 특정 분류로 나뉘게 될때 쓰입니다. 따라서 Logistic Regression은 회귀분석이지만 분류성격을 갖고 있습니다."],"metadata":{"id":"W1EJ2SwMj-Gf"}},{"cell_type":"markdown","source":["2.이웃 기반 방법\n","\n","다음으로는 이웃 기반 방법입니다. 대표적인 알고리즘은 KNN으로 자세히 짚어보고 넘어가겠습니다.\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5d2afc64-e7ee-4b04-b280-0a5e83e40ecb/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T021805Z&X-Amz-Expires=86400&X-Amz-Signature=d70b98e81152140c2aa7068e244c35e9032ea7f3b76031704a1b8d1902aaaff7&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"600\" height=\"150\">\n","\n","KNN은 비슷한 특성이나 속성을 가진 것들끼리 가깝게 모여있는 이웃의 속성에 따라 k개씩 분류하여 레이블링을 하는 알고리즘입니다. \n","\n","각각의 새로운 데이터 포인트에 레이블을 지정하기 위해 K개 (K는 정수)의 가장 가까운 레이\n","블이 지정된 데이터 포인트를 보고 이미 레이블이 지정된 이웃들에게 새로운 데이터 포인트에 레이블을 지정하는 방법을 투표하게 합니다. \n","\n","또한 KNN은 유클리드 거리와 맨해튼 거리를 사용합니다. KNN은 K값의 선택이 매우 중요한데 매우 작은 값으로 설정될 경우 과대적합의 위험이, 매우 큰 값으로 설정될 경우 과소적합의 위험이 있어 K값을 적당하게 선정해야 합니다."],"metadata":{"id":"Hf5qUzN3kDrU"}},{"cell_type":"markdown","source":["3.트리 기반 방법\n","\n","01)단일 의사 결정 트리\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8a5a64f3-a626-4a38-879f-c80160bc51da/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T021926Z&X-Amz-Expires=86400&X-Amz-Signature=cc3946191c77637a38a963552af63d9358bd97cd2d0b4dfb7dc3f5bcbd33c10a&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"450\" height=\"200\">\n","\n","\n","AI가 훈련 데이터를 한번 통과한 후 레이블에 의해 데이터를 분할하는 규칙을 만들고, 만들어진 트리를사용해 새로운 검증 또는 테스트 데이터셋을 예측하는 방법입니다.\n","\n","최대한 균일한 데이터 세트를 구성할 수 있도록 분할 하는 것이 중요하며 분류 및 회귀 모델을 구축하는데 사용됩니다. 단일 의사 결정 트리는 쉬운 시각화로 가독성이 높으며, 변수의 정규화가 필요없고 X Y의 인과관계와 종속변수간 영향력 파악이 쉽다는 장점이 존재합니다. \n","\n","그러나 알고리즘이 심플한 만큼 예측력이 떨어지고, 과대적합이 발생하여 일반화 성능이 저해됩니다. 즉 새 데이터가 적용될 경우 낮은 예측력이 나오며 이를 개선 시키기 위한 알고리즘은 랜덤 포레스트 입니다."],"metadata":{"id":"Wnmlf3bokXP-"}},{"cell_type":"markdown","source":["02)랜덤포레스트\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3b09c7f5-71ba-4970-b7de-eeb54a596679/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T022046Z&X-Amz-Expires=86400&X-Amz-Signature=0f09f543fbf8ebd959674c0955c14f3010f2d290bafff5c3ca55f672ac2f8561&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"500\" height=\"400\">\n","\n","랜덤 포레스트 알고리즘은 단일 의사 결정 트리의 분류보다 정확도를 개선시키기 위해, 여러 개의 나무(단일 의사 결정 트리 모델)를 생성한 후 각각의 예측을 조합하여 결론을 내는 구조입니다.\n","\n","다수의 나무들로부터 분류를 집계하기 때문에 과대적합이 나타나는 나무의 영향력을 줄일 수 있습니다. (예측 모델의 일반화 성능이 향상됩니다.) 또한 단일 의사 결정 트리에 비해 과대적합이 잘 되지 않습니다.\n","\n","그러나 트리를 많이 생성하다 보니 개별 트리 분석이 어렵고 트리 분리가 복잡해집니다. 또한 차원이 크고 희소한 데이터에 대해서는 성능이 미흡합니다."],"metadata":{"id":"kKjOJ20NkrOY"}},{"cell_type":"markdown","source":["3.SVM\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9b04a1a1-1d0b-4f02-b6db-88a9a98dbce6/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T022225Z&X-Amz-Expires=86400&X-Amz-Signature=8368b9cd794e843e890105f892e316c4a57751eb0f3940fdb7f82bcbd12779b4&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"400\" height=\"400\"> \n","\n","데이터를 분리하기 위해 트리를 만드는 대신 알고리즘을 사용해 데이터를 분리하는 공간에 초평면 (hyperplane)을 만들어 레이블에 의해 데이터를 분리하는 방법입니다.\n","\n","[🤚잠깐, ‘초평면’이란?🤚\n","\n"," 어떤 N차원 공간에서 한차원 낮은 N-1차원의 subspace를 말합니다. \n","\n","3차원에서는 면이 초평면이며, 2차원에서는 선이 초평면입니다.]\n","\n","딥러닝 이전 뛰어난 성능으로 많은 주목을 받았던 서포트 벡터 머신으로 분류되지 않은 새로운 점이 나타나면 경계의 어느 쪽에 속하는지 확인해서 분류 과제를 수행합니다. 결정경계는 클래스간 경계가 균일하면서 클래스 내에서 거리가 먼 경우 선택합니다. \n","\n","오류 데이터의 영향이 적고, 과적합 되는 경우가 적다는 장점이 있지만 최적의 모델을 찾기 위해서 커널과 모델에서 다양한 테스트가 필요하고, 학습 속도가 느리며 해석이 어렵기도 합니다."],"metadata":{"id":"et3Rbg2Uk-pv"}},{"cell_type":"markdown","source":["4.지도 학습의 이상 탐지 기법\n","\n","지도 학습은 비지도 학습과 다르게 이상 탐지 기법에서 실무에 적용되기 어려운 기법입니다.😢\n","\n","훈련 데이터의 모든 개체에 라벨링이 되어 있을시 쓰는 방법인데, 데이터는 정상에 비해 이상의 \n","\n","비율이 적은 불균형한 상태에 있으며 정확한 분류가 어렵습니다. \n","\n","또한 정황상 이상한 것이 맞다고 판단하여도 판별할 관측데이터가 없는 경우 결과적으로 알아낼 수 없습니다. **따라서 지도 학습은 실무에서 적용하기 힘든 기법입니다.**"],"metadata":{"id":"oZONhsnjlUEL"}},{"cell_type":"markdown","source":["### **3.비지도 학습 기반의 알고리즘 및 이상탐지 기법**"],"metadata":{"id":"L92BDAHwczZX"}},{"cell_type":"markdown","source":["1. 비지도 학습의 정의\n","    \n","비지도 학습은 정답 라벨이 없는 데이터를 비슷한 특징끼리 군집화하여 새로운 데이터에 대한 결과를 예측하는 것을 말합니다. 정답 라벨이 없기 때문에 엄격하게 정의된 레이블이 없으므로 더 흥미로운 패턴을 발견할 수도 있는 장점이 있습니다.\n","    \n","그럼 비지도 학습에 대한 모델링 기법은 어떤 방법들이 있는지 공부해 볼까요?🙂\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/16b2526b-f5f0-44d8-94f4-0abf9d2a51b1/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T022544Z&X-Amz-Expires=86400&X-Amz-Signature=015a323e985413a8cad58f7720afec0d46a1c723fff1f9c778f07f0d44054437&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"500\" height=\"300\">\n","\n","\n","2. 차원의 저주\n","    \n","모델링에 대해서 공부하기 전, 우리는 차원의 저주를 공부해 볼 필요가 있어요!\n","    \n","아래의 그림을 보시면 feature의 수가 많아지게 되면 dimension의 수도 증가하기 때문에 공간의 부피가 기하급수적으로 증가하는 것을 볼 수가 있어요. 그렇게 되면 빈 공간이 많이 생기기 때문에 모델이 학습을 하는데 불완정해질 수도 있고, overfitting의 위험도 있어요. 그럼 어떻게 이 문제를 해결할 수 있을까요? 🧐  \n","    \n","우리는 차원 축소를 통해 이 문제를 해결하려고 합니다.\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/a6eb35ac-8bd7-4ea4-9c11-a78dc597a50c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T022657Z&X-Amz-Expires=86400&X-Amz-Signature=c18d1fc68595e903a454642a1aa3ddac97bad315353364cddb61fa3f763446ad&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"600\" height=\"200\">\n","\n"],"metadata":{"id":"UL5oo_o8lzp-"}},{"cell_type":"markdown","source":["3. 차원 축소\n","    \n","차원 축소에서도 선형과 비선형으로 구분되는데 다음 그림을 보면 여러 가지의 모델링 방법들이 있는 것을 확인할 수 있어요. :)\n","    \n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/5637bbdd-e5b4-489a-a7dd-462c5ce78e8a/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T022852Z&X-Amz-Expires=86400&X-Amz-Signature=a1593586ef8953c962e9a0b1a161e664586b8e1fb102c9ca08d0edfcaf6303fe&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"600\" height=\"200\">\n","    \n","그럼 선형과 비선형은 어떻게 정의되고, 차원 축소와 관련된 모델링 방법들에 대한 이론에 대해서 간단히 설명해 보도록 할게요!\n","    \n","3-1. 차원 축소 (선형)\n","    \n","아래 왼쪽 그림을 보시면 3차원 공간에 존재하는 데이터들이 어떤 평면상(부분공간)에 투영되어서 오른쪽 그림과 같이 2차원 공간으로 축소되는 모습을 선형 차원 축소라고 합니다.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/317c1d54-6cb3-4b20-a2ba-5a473ff23547/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T022742Z&X-Amz-Expires=86400&X-Amz-Signature=e7aaa91b5657473e7644c01c3801ab747201ebdd12c021964df83850d54ada83&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"600\" height=\"200\">\n","    \n","3-2. 차원 축소 (비선형)\n","    \n","그럼 비선형은 어떻게 차원 축소를 할까요?\n","    \n","비선형 차원 축소는 매니폴드 학습(Manifold Learning)으로 불리기도 하는데, 아래 왼쪽 그림을 보시는 것처럼 말려져 있는 데이터를 하나의 평면으로 본다고 가정하는 거예요! 그래서 오른쪽 그림을 보시면 선형과 비선형으로 차원 축소한 모습을 나타냈는데, 비선형으로 차원 축소한 모습이 더 잘 분류한 것을 알 수 있어요 🙂\n","    \n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9de40de1-e58d-4485-a496-4b51ed184b23/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T030835Z&X-Amz-Expires=86400&X-Amz-Signature=3e4e75343112c3f5fa94f159aabde7072d95cdfa901eb9d5187be2d0538e5148&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"600\" height=\"200\">\n","    \n","하지만 비선형 차원 축소도 단점은 분명히 존재하는데 고차원에서 Decision boundary를 찾는 것이 더 편리할 수 있기 때문에, 데이터를 확인하면서 선형으로 축소할 것인지, 비선형으로 축소할 것인지 결정해야 돼요 :)\n","    \n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/4ec3b472-c7cb-4a27-bc86-4d9e42b96fef/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T030930Z&X-Amz-Expires=86400&X-Amz-Signature=fadce5372a371fdaa01d726d6d6954cfc915ec1bdeefd991ef8fd85d16e31563&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"600\" height=\"250\">\n"],"metadata":{"id":"m44u0eS5w2S0"}},{"cell_type":"markdown","source":["4. 비지도 학습 모델 (차원 축소)\n","    \n","4-1. Principal Component Analysis (PCA, 선형)\n","    \n","데이터의 변동성을 설명할 때 전체 feature 중 어떤 feature가 가장 중요한지 파악하는 것이 중요한데, 이때 PCA 알고리즘을 이용할 수 있어요! PCA 알고리즘이란 최대한 다양성을 유지하면서 데이터의 저차원 표현을 찾는 방법이에요. 아래 그림을 보시는 것처럼 x1과 x2의 관계 중에서 저차원으로 이동시킬 때, 데이터를 잘 보존하기 위해서 분산을 최대로 하는 c1 축을 찾는 것이 PCA의 특징이에요.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/378b0b3e-45a3-47c1-b7e5-3ac09f9eed0c/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T031921Z&X-Amz-Expires=86400&X-Amz-Signature=dce333e36de70e077d634c367c69bc88bf38bff847d5c6d4e9c244db217f38ad&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"400\" height=\"300\">\n","    \n","기존 PCA 방법 외에도 여러 가지로 변형된 Incremental PCA, Kernel PCA, Sparse PCA등이 있답니다!\n","    \n","4-2. Singular Value Decomposition (SVD, 선형)\n","    \n","원래 행렬의 차원을 적은 차원으로 줄여 더 작은 차원의 행렬에서 일부 벡터의 선형 결합을 사용해 원래 행렬을 다시 만들 수 있도록 합니다.\n","    \n","4-3. t-distributed stochastic neighbor embedding (t-SNE, 비선형)\n","    \n","t-SNE의 기본적인 원리는 고차원의 데이터간 거리를 저차원으로 축소하였을 때,똑같이 유지하는 것입니다. 따라서 원 공간에서 가까운 점들도 고려하고, 좀 더 멀리 있는 점들의 위치도 고려하는 방법입니다. 다음 그림을 보시면 이해하기 쉬울 거예요. 🙂\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/98515c60-139b-4a98-8ab8-2e9479a2d4cb/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T031952Z&X-Amz-Expires=86400&X-Amz-Signature=21d84ad53d6819f6fa9e3430cfaba5f85906eb20ab7f28d36e8b6fbbacd004af&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"500\" height=\"350\">\n","    \n","1번 그림을 보시면 3차원의 데이터가 존재하는데 이 데이터를 2차원으로 축소해서 최종적으로 4번의 그림처럼 각 데이터의 거리를 유지시키는 방법이에요. 1번 그림에서 각 포인트마다 기준을 정하고, 정규분포를 이용하여 유사도를 시각화해서 나타냅니다. 2번 그림에서는 원래의 데이터들을 랜덤으로 2차원 공간에 배치시켜서 t 분포의 특성(꼬리 부분이 두꺼움)을 이용하여 나타냅니다. 이 과정을 반복해서 최종적으로 4번 그림과 같이 저차원의 데이터로 이동시켜서 거리를 유지해 주도록 합니다. 아래 그림처럼 t 분포를 이용하여 고차원에서 유사도(y축)가 높은 관계면 데이터 포인트를 더 가까이 배치시키고, 낮은 관계면 더 멀리 배치할 수 있도록 합니다.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3a65ea54-a02c-4ef7-9146-f26a6e897e54/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032036Z&X-Amz-Expires=86400&X-Amz-Signature=cee95ba3034d6773b242a9c51b9ff54ebce160b5acc6401bdb88735fad302f4a&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"250\" height=\"250\">\n","    \n","4-4. Autoencoder (비선형)\n","    \n","오토인코더는 비지도 학습 기반의 대표적인 방법입니다. 입력 샘플을 인코더를 통해 저차원으로 압축 시키고, 디코더 과정을 거쳐서 다시 원래의 차원으로 복원하는 방법이에요. 오터인코더의 특징 중 하나는 디코더를 통해 원래의 차원으로 복원하는 방법인데, 이 방법을 통해서 입력 샘플과 복원 샘플의 복원 오차 (reconstruction error)를 산출할 수 있어요. 😃\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8b7e9fb4-c50e-45c7-849e-86fe212ee330/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032106Z&X-Amz-Expires=86400&X-Amz-Signature=2b9a3700d2fac16801898eddaf4b270b35f56c70c38dc311aeacc9a31df3fb94&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"300\">"],"metadata":{"id":"I8Llphe5wfrn"}},{"cell_type":"markdown","source":["5. 비지도 학습 모델 (클러스터링)\n","\n","    \n","5-1. LOF (Local Outlier Factor)\n","    \n","local 이상값을 찾기 위해 설계된 밀도 기반 방법입니다. \n","    \n","1) 각 데이터 포인트에 대해 NN이 계산\n","    \n","2) 계산된 이웃을 사용하여 로컬 밀도 계산 (LRD)\n","    \n","3) 데이터 포인트의 LRD와 이전에 계산된 NN의 LRD 비교하여 LOF 계산해서 다른 개체보다 밀도가 낮게 특정 되는 데이터를 이상치로 판단합니다.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3f5baf8b-9225-446a-9ff5-bdd33e70431e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032151Z&X-Amz-Expires=86400&X-Amz-Signature=657ba0ee9684ed8a986a22a1ae63390a05f213df08f1b98c3bcd855893046851&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"550\" height=\"200\">\n","    \n","5-2. K-means\n","    \n","데이터를 특성에 따라 k개의 그룹으로 클러스터링하는 알고리즘입니다. 클러스터의 중심에서 멀리 떨어진 데이터는 비정상 데이터로 판단합니다. \n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9135929b-6086-456f-8b7a-1d003c098f03/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032243Z&X-Amz-Expires=86400&X-Amz-Signature=2016b08a91e2087e6c69a4db8e347482a25e0bb535388cc3f620a9bfb8836d38&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"200\">\n","    \n","5-3. rPCA (Robust Principal Component Analysis)\n","    \n","차원을 축소하고 복원을 하는 과정을 통해 비정상 sample을 검출하는 방법입니다. 데이터를 더 낮은 차원의 부분공간으로 보내면 그 공간에서는 정상과 이상이 구분된다고 가정합니다.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/113ea088-0ad8-43ec-bed9-f74344cfc6d1/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032547Z&X-Amz-Expires=86400&X-Amz-Signature=47cf4577a1b509ac72b464d2a95f0c4d6874dbd092a88aaffbd50a47398b3199&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"200\">\n","    \n","5-4. Isolation Forest\n","    \n","비정상 데이터는 의사결정나무의 루트에서 가까운 깊이에 고립 될 것이라고 가정합니다. 따라서 leaf 노드 까지의 거리를 outlier score로 정의하고, 평균 거리가 짧을 수록 outlier일 가능성이 크다고 판단합니다.\n","\n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/c24c5bcf-bd14-4f89-99a6-3de05d78c34b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032632Z&X-Amz-Expires=86400&X-Amz-Signature=a605bbb5122eecca913f64c3ee09da694444c7fb46e46f4294c9ed0918afe84f&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"200\">\n","\n","5-5. One Class SVM\n","    \n","정상 데이터를 원점으로부터 최대한 멀리 위치하게 만드는 초평면(Hyperplane)을 찾고, 새로운 데이터가 원점과 초평면 사이에 위치하면 이상치 데이터로 판별하는 알고리즘입니다.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ca120038-d18d-4f36-97bd-7d6f01e39dbb/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032707Z&X-Amz-Expires=86400&X-Amz-Signature=232c1dd9350c31bc2215ad718cecfa4848edb99d58b0c988dbf93912840057e6&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"200\">\n","    \n","5-6. Angle Based Outlier detection (ABOD)\n","    \n","각도 기반 이상치 감지 알고리즘입니다. 데이터 포인트와 다른 포인트 사이의 각도 분산을 이상 점수로 이용됩니다.\n","    \n","<img src=\"https://s3.us-west-2.amazonaws.com/secure.notion-static.com/55e11e79-5e32-4f3d-ab4a-3d580d8c2ed3/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20220412%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20220412T032739Z&X-Amz-Expires=86400&X-Amz-Signature=b7beb0b5bc6a614fd01ae9db9972c8656df532c2faae224c75ee3371539f6f1c&X-Amz-SignedHeaders=host&response-content-disposition=filename%20%3D%22Untitled.png%22&x-id=GetObject\" width=\"300\" height=\"200\">"],"metadata":{"id":"_NaPwxp4wgbK"}},{"cell_type":"markdown","source":["6**.** 비지도 학습의 이상탐지\n","\n","비지도 학습은 레이블을 사용할 수 없어 AI 에이전트의 작업이 명확히 정의되지 않습니다. 그러나 엄격하게 정의된 작업이 없는 만큼 더 흥미로운 패턴을 발견할 수 있으며 제대로 활용히 아주 강력한 솔루션이 됩니다. 일반적으로 신용카드 사기, 통신 금융 사기 등 다양한 사기 탐지에 사용되며 악의적이고 드문 이벤트를 식별하는 데도 사용됩니다. 😃"],"metadata":{"id":"8SvZTDLKwmOL"}},{"cell_type":"markdown","source":["### **참고 자료**\n","\n","- 차원 축소 및 PCA\n","    \n","[https://excelsior-cjh.tistory.com/167?category=918734](https://excelsior-cjh.tistory.com/167?category=918734)\n","    \n","- t-SNE\n","    \n","[https://gaussian37.github.io/ml-concept-t_sne/#](https://gaussian37.github.io/ml-concept-t_sne/#)\n","    \n","- 클러스터링\n","    \n","[https://medium.com/analytics-vidhya/algorithm-selection-for-anomaly-detection-ef193fd0d6d1](https://medium.com/analytics-vidhya/algorithm-selection-for-anomaly-detection-ef193fd0d6d1)\n","    \n","- 이상탐지 활용 사례\n","    \n","[https://kh-kim.github.io/blog/2019/12/12/Deep-Anomaly-Detection.html](https://kh-kim.github.io/blog/2019/12/12/Deep-Anomaly-Detection.html)\n","    \n","[https://leedakyeong.tistory.com/entry/Anomaly-Detection-by-Auto-Encoder](https://leedakyeong.tistory.com/entry/Anomaly-Detection-by-Auto-Encoder)\n","    \n","- knn\n","\n","[https://bskyvision.com/563](https://bskyvision.com/563)\n","\n","- svm\n","\n","[https://hleecaster.com/ml-svm-concept/](https://hleecaster.com/ml-svm-concept/)"],"metadata":{"id":"tp4tp35GlS-o"}}]}